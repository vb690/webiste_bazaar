{
  "hash": "ea1884f32e61d9870ca4ce6998a758c8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Analyzing A/B Test Data using Gaussian Processes\ndescription: 'This post illustrates how to analyze longitudinal A/B test data using Gaussian Process.'\ndate: '2025-03-29'\ncategories:\n  - JAX\n  - Numpyro\n  - Bayesian Statistics\n  - A/B Test\n  - Gaussian Process\nbibliography: bibliographies/ab_test_gp.bib\njupyter: python3\n---\n\n::: {#b1098c13 .cell vscode='{\"languageId\":\"python\"}' execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\n%load_ext watermark\n\nfrom typing import Dict, Any, Callable, Tuple\n\nfrom functools import partial\n\nimport pandas as pd\nimport numpy as np\n\nimport scipy\nfrom scipy.stats import lognorm, median_abs_deviation\n\nimport jax\nfrom jax.typing import ArrayLike\nimport jax.random as random\nfrom jax import jit\nfrom jax import numpy as jnp\nfrom jax import vmap\n\nimport numpyro\nimport numpyro.distributions as dist\nfrom numpyro.infer import (\n    MCMC,\n    NUTS,\n    Predictive\n)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.figure import Figure\nfrom matplotlib import gridspec\n\nimport seaborn as sns\n\ndef plot_univariate_series(\n        series_data: Dict[Any, Any], \n        ax: plt.Axes, \n        **plot_kwargs: Any\n    ) -> plt.Axes:\n    ax.scatter(\n        series_data[\"x\"][\"data\"],\n        series_data[\"y\"][\"data\"],\n        **plot_kwargs\n    )\n    ax.plot(\n        series_data[\"x\"][\"data\"],\n        series_data[\"y\"][\"data\"],\n        **plot_kwargs\n    )\n    ax.set_xlabel(series_data[\"x\"][\"label\"])\n    ax.set_ylabel(series_data[\"y\"][\"label\"])\n\n    ax.tick_params(\n        direction=\"in\",\n        top=True, axis=\"x\",\n        rotation=45,\n    )\n    ax.grid(\n        visible=True,\n        which=\"major\",\n        axis=\"x\",\n        color=\"k\",\n        alpha=0.25,\n        linestyle=\"--\",\n    )\n    return ax\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe watermark extension is already loaded. To reload it, use:\n  %reload_ext watermark\n```\n:::\n:::\n\n\n# Premise\n\n## What we will cover\n\n## What we will **not** cover\n\n# Introduction\n\n::: {#d8166f5f .cell execution_count=2}\n``` {.python .cell-code}\nBLUE = (0, 83, 159)\nBLUE = tuple(value / 255. for value in BLUE)\n\nRED = (238, 28, 46)\nRED = tuple(value / 255. for value in RED)\n\nTIME_IDX = np.arange(7*6)\nDATES = pd.date_range(\n    start=\"01-01-2023\",\n    periods=len(TIME_IDX)\n).values\nTIME = \"date\"\nMODELS = [\n    \"Branch A\",\n    \"Branch B\",\n    \"Branch C\",\n    \"Branch D\",\n    \"Branch E\",\n]\n```\n:::\n\n\n## A/B tests and longitudinal A/B tests\n\n## Gaussian Process\n\n## Gaussian Process for A/B test\n\n# Implementing a Gaussian Process Model in Numpyro\n\n## Kernel Functions\n\n::: {#0c662f00 .cell vscode='{\"languageId\":\"python\"}' execution_count=3}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\ndef simulate_kernel(\n    X: ArrayLike, \n    X_prime:ArrayLike, \n    kernel_function: Callable, \n    samples: int\n) -> Tuple[ArrayLike, ArrayLike, ArrayLike]:\n    generated_covariance = kernel_function(\n        X=X,\n        X_prime=X_prime,\n    )\n    distance = generated_covariance[:, len(X) // 2]\n    sampled_functions = np.random.multivariate_normal(\n        mean=np.zeros(\n            shape=generated_covariance.shape[0]\n        ),\n        cov=generated_covariance,\n        size=samples\n    )\n    return generated_covariance, distance, sampled_functions\n\ndef visualize_kernel(\n    X: ArrayLike, \n    generated_covariance: ArrayLike, \n    distance: ArrayLike, \n    sampled_functions: ArrayLike, \n    kernel_name: str\n) -> Figure:\n\n    fig = plt.figure(\n        figsize=(8, 8),\n        tight_layout=True\n    )\n    grid = gridspec.GridSpec(\n        nrows=2,\n        ncols=2\n    )\n    ax_functions = fig.add_subplot(grid[0, :])\n    ax_distance = fig.add_subplot(grid[1, 0])\n    ax_covariance = fig.add_subplot(grid[1, 1])\n\n    for index in range(sampled_functions.shape[0]):\n\n        ax_functions = plot_univariate_series(\n            series_data={\n                \"x\": {\n                    \"data\": X,\n                    \"label\": \"x\"\n                },\n                \"y\": {\n                    \"data\": sampled_functions[index, :],\n                    \"label\": \"y\"\n                },\n\n            },\n            ax=ax_functions,\n            alpha=0.5\n        )\n\n    ax_functions.set_title(\"Sampled Functions \\n from MvNormal\")\n    ax_functions.axhline(0, linestyle=\"--\", c=\"k\")\n\n    ax_distance.plot(\n        X - (len(X) // 2),\n        distance\n    )\n    ax_distance.grid(alpha=0.5)\n    ax_distance.set_title(f\"Distance Function \\n Determined by {kernel_name} Kernel\")\n    ax_covariance.set_ylabel(\"Similarity\")\n    ax_covariance.set_xlabel(\"Distance\")\n\n    ax_covariance.imshow(\n        generated_covariance\n    )\n    ax_covariance.set_ylabel(\"x'\")\n    ax_covariance.set_xlabel(\"x\")\n    ax_covariance.set_title(f\"Covariance \\n Determined by {kernel_name} Kernel\")\n\n\n    plt.suptitle(f\"{kernel_name} Kernel\")\n    return fig\n```\n:::\n\n\n## The Gaussian Process Model\n\n### Radial Basis Function Kernel\n\n::: {#fc103cfb .cell execution_count=4}\n``` {.python .cell-code}\n@jit\ndef RBF_kernel(\n    X: ArrayLike, \n    X_prime: ArrayLike, \n    variance: float, \n    length: float, \n    noise: float,\n    jitter: float =1.0e-6, \n    include_noise: bool =True\n):\n    squared_differences = jnp.power(\n        (X[:, None] - X_prime),\n        2.0\n    )\n    squared_length_scale = 2 * jnp.power(\n        length,\n        2.0\n    )\n    covariance_matrix = jnp.exp(\n        - (squared_differences / squared_length_scale)\n    )\n    scaled_covariance_matrix = variance * covariance_matrix\n\n    if include_noise:\n        scaled_covariance_matrix += (noise + jitter) * jnp.eye(X.shape[0])\n\n    return scaled_covariance_matrix\n```\n:::\n\n\n::: {#3e930a10 .cell execution_count=5}\n``` {.python .cell-code}\nkernel_function = partial(\n    RBF_kernel,\n    variance=1,\n    length=10,\n    noise=0.001\n)\ngenerated_covariance, distance, sampled_functions = simulate_kernel(\n    X=TIME_IDX,\n    X_prime=TIME_IDX,\n    kernel_function=kernel_function,\n    samples=3,\n)\nfig = visualize_kernel(\n    TIME_IDX,\n    generated_covariance=generated_covariance,\n    distance=distance,\n    sampled_functions=sampled_functions,\n    kernel_name=\"RBF\"\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](ab_test_gp_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\n### Matern Kernel\n\n::: {#469b09d3 .cell execution_count=6}\n``` {.python .cell-code}\n@jit\ndef rational_quadratic_kernel(\n    X: ArrayLike, \n    X_prime: ArrayLike, \n    variance: float, \n    length: float, \n    noise: float, \n    alpha: float, \n    jitter: float =1.0e-6, \n    include_noise: bool =True\n):\n\n    squared_differences = jnp.power(\n        (X[:, None] - X_prime),\n        2.0\n    )\n    squared_length_scale = 2 * alpha * jnp.power(\n        length,\n        2.0\n    )\n    covariance_matrix = jnp.power(\n        1 + (squared_differences / squared_length_scale),\n        - alpha\n    )\n    scaled_covariance_matrix = variance * covariance_matrix\n\n    if include_noise:\n        scaled_covariance_matrix += (noise + jitter) * jnp.eye(X.shape[0])\n\n    return scaled_covariance_matrix\n```\n:::\n\n\n::: {#6340f2eb .cell execution_count=7}\n``` {.python .cell-code}\nkernel_function = partial(\n    rational_quadratic_kernel,\n    variance=1,\n    length=10,\n    alpha=3,\n    noise=0.001\n)\ngenerated_covariance, distance, sampled_functions = simulate_kernel(\n    X=TIME_IDX,\n    X_prime=TIME_IDX,\n    kernel_function=kernel_function,\n    samples=3\n\n)\nfig = visualize_kernel(\n    TIME_IDX,\n    generated_covariance=generated_covariance,\n    distance=distance,\n    sampled_functions=sampled_functions,\n    kernel_name=\"Rational Quadratic\"\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](ab_test_gp_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\n# Simulating the data\n\n# Fitting Gaussian Process Models to A/B test data\n\n# Visualize the results\n\n# Conclusion\n\n# Hardware and Requirements\nHere you can find the hardware and python requirements used for building this post.\n\n::: {#d02ef14b .cell execution_count=8}\n``` {.python .cell-code}\n%watermark\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLast updated: 2025-03-29T19:28:02.074793+00:00\n\nPython implementation: CPython\nPython version       : 3.13.2\nIPython version      : 9.0.2\n\nCompiler    : Clang 18.1.8 \nOS          : Darwin\nRelease     : 24.3.0\nMachine     : arm64\nProcessor   : arm\nCPU cores   : 14\nArchitecture: 64bit\n\n```\n:::\n:::\n\n\n::: {#c18d209d .cell execution_count=9}\n``` {.python .cell-code}\n%watermark --iversions\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nnumpyro   : 0.18.0\npandas    : 2.2.3\nscipy     : 1.15.2\nmatplotlib: 3.10.1\nseaborn   : 0.13.2\nnumpy     : 2.2.4\njax       : 0.5.2\n\n```\n:::\n:::\n\n\n",
    "supporting": [
      "ab_test_gp_files"
    ],
    "filters": [],
    "includes": {}
  }
}