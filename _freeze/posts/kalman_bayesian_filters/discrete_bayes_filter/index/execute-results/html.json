{
  "hash": "e70bbe258169f78f41e9e9d0c36bd361",
  "result": {
    "markdown": "---\ntitle: Chapter 2 - Discrete Bayes Filter\ndescription: This post illustrates how to incorporate concepts borrowed from bayesian statistics into filtering algorithms.\nauthor: Valerio Bonometti\ndate: '2023-02-25'\ncategories:\n  - Kalman and Bayesian Filters\n  - Discrete Bayes Filter\n  - Bayesian Statistics\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nfrom jax import jit\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n# Bayes for Filtering\n\nIn order to move from the gh filter presented in the previous post to the Kalman filter we need to introduce some concepts borrowed from Bayesian statistics. A comprehensive introduction to the topic is beyond the aim of this post, for which we suggest the fantastic book by Richard McElreath [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/).\n\n## Updating Beliefs\n\nAs we have seen before the gh filter relied consistently on the idea of generating predictions given our knowledge of the state of a system and adjusting these as soon as we had observable measurements. It turns out that bayesian statistics offers a convenient and formal framework for doing this type of belief updates. Let's look at a concrete example\n\nLet's say that we are trying to estimate the position of an agent within an environment with a certain number of obstacles. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom jax import random\nimport jax.numpy as jnp\n\nmaster_key = random.PRNGKey(666)\n\nobservations = random.choice(key=master_key, a=jnp.array([0., 1.]), shape=(10,), p=jnp.array([.4, .6]))\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\nax.bar(\n    x=np.arange(len(observations)),\n    height=observations,\n    color=\"r\"\n)\nax.set_ylabel(\"Observation\")\nax.set_xlabel(\"Position\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=515 height=356}\n:::\n:::\n\n\nWithout receiving any measurement from the agent our belief, we will call it prior from now on, on its position is distributed equally on all the available locations\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\npriors = jnp.array([1. / len(observations)] * len(observations))\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 4))\nax.bar(\n    x=np.arange(len(observations)),\n    height=priors\n)\nax.set_title(\"Prior\")\nax.set_ylabel(\"Probability\")\nax.set_xlabel(\"Position\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){width=523 height=376}\n:::\n:::\n\n\nThe measurements we receive from the agent will tell us if, in its current state, it is facing an obstacle or not. We can quantify our knowledge in light of a measurement though a likelihood function\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n@jit\ndef custom_likelihood(measurement, observations, p):\n    \"\"\"Compute the likelihood of the agent being in\n    each potion of the observations space given a measurement\n    and the probability of an obstacle\n\n    Args:\n        - measurement(int): measurement from the agent.\n        - observations(DeviceArray): possible locations of the agent.\n        - p (float): probability that the measurement is providing correct information\n\n    Returns:\n        - likelihood(DeviceArray): likelihood of the agent \n        position in the observation space.\n    \"\"\"\n    likelihood = jnp.ones(shape=(len(observations), ))\n    likelihood = jnp.where(\n        observations == measurement,\n        likelihood * (p / (1-p)),\n        likelihood\n    )\n    return likelihood\n\nlikelihood_obstacle = custom_likelihood(\n    measurement=1,\n    observations=observations,\n    p=.75\n)\nlikelihood_path = custom_likelihood(\n    measurement=0,\n    observations=observations,\n    p=.75\n)\n\nfig, axs = plt.subplots(1, 2, figsize=(6, 3), sharex=True, sharey=True)\n\naxs[0].bar(\n    x=np.arange(len(observations)),\n    height=likelihood_obstacle\n)\naxs[0].set_title(\"Likelihood Measurement\\nObstacle\")\n\naxs[1].bar(\n    x=np.arange(len(observations)),\n    height=likelihood_path\n)\naxs[1].set_title(\"Likelihood Measurement\\nPath\")\n\naxs[0].set_ylabel(\"Density\")\naxs[0].set_xlabel(\"Position\")\naxs[1].set_xlabel(\"Position\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=553 height=277}\n:::\n:::\n\n\nand subsequently update our priors in view of the likelihood derived from the measurements using bayes theorem $posterior \\propto likelihood \\times prior$\n\n::: {.cell execution_count=5}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\ndef plot_posterior_derivation(priors, likelihood, posterior):\n\n    fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\n\n    axs[0].bar(\n        x=np.arange(len(priors)),\n        height=priors \n    )\n    axs[0].set_title(\"Priors Position\")\n\n    axs[1].bar(\n        x=np.arange(len(likelihood)),\n        height=likelihood / likelihood.sum()\n    )\n    axs[1].set_title(\"Likelihood Measurement\\nObstacle\")\n\n    axs[2].bar(\n        x=np.arange(len(posterior)),\n        height=posterior\n    )\n    axs[2].set_title(\"Posterior Position\")\n\n    axs[0].set_ylabel(\"Probability\")\n    for ax in axs:\n\n        ax.set_xlabel(\"Position\")\n\n    plt.tight_layout()\n    plt.show()\n```\n:::\n\n\nSince our priors were not providing any information the posterior we obtained was driven exclusively byt the likelihood\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n@jit\ndef custom_update(priors, likelihood):\n    \"\"\"Update priors about agent position given likelihood of the measurement\n\n    Args:\n        - priors(DeviceArray): priors on the agent position.\n        - likelihood(DeviceArray): likelihood of the agent position after observing a measurement.\n\n    Returns:\n        - posterior(DeviceArray): posterior probability of the agent \n        position in the observation space.\n    \"\"\"\n    posterior = priors * likelihood\n    return posterior / jnp.sum(posterior)\n\nlikelihood = custom_likelihood(\n    measurement=1,\n    observations=observations,\n    p=.75\n)\nposterior = custom_update(\n    priors=priors,\n    likelihood=likelihood\n)\n\nplot_posterior_derivation(\n    priors=priors, \n    likelihood=likelihood, \n    posterior=posterior\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=845 height=277}\n:::\n:::\n\n\nHowever it is easy enough to see how things change if we provide priors that are slightly more informative\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\npriors = jnp.array(\n    [\n        0.2,\n        0.4,\n        0.2,\n        0.05,\n        0.05,\n        0.02,\n        0.02,\n        0.02,\n        0.02,\n        0.02\n    ]\n)\nposterior = custom_update(\n    priors=priors,\n    likelihood=likelihood\n)\n\nplot_posterior_derivation(\n    priors=priors, \n    likelihood=likelihood, \n    posterior=posterior\n)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=853 height=277}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}