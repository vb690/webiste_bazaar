{
  "hash": "d32abc1038ee886a2d1140ba75130441",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Chapter 1 - The g-h Filter\" \ndescription: \"This post introduces the rudimentary of filtering with a particular focus on the g-h filter.\"\nauthor: \"Valerio Bonometti\"\ndate: \"2023-08-24\"\ncategories: [JAX, Tutorial, Kalman and Bayesian Filters, g-h Filter]\njupyter: python3\n---\n\n::: {#99d8e2bf .cell execution_count=1}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nimport numpy as np\n\nfrom itertools import product\n\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n# Why do we need filtering?\n\nWhen we take measurements in the real world we are often interested in quantifying a process or a phenomenon underlying such measures. If these measurements are acquired through imprecise methodologies it is important to be able to separate the true \"signal\" representative of the process of interest from the noise, filtering offers us a way for addressing this problem.\n\nOne obvious solution might be to take multiple measurements and derive the expected signal from them. Unfortunately this option can become problematic in situations when the noise is very large or it is hard to gather measurements. In some situations for example we might have access to only a single measure acquired over time (e.g., financial or economical time series). In these cases we want to use everything we have in order to derive our estimate, in other words we **do not discard information**.\n\nFiltering helps us making effective use of past information by using it for performing **prediction** that are then used for **weighting and updating** current noisy observations. In reality, both predictions and observations are assumed to be inherently noisy hence a natural framework for developing filtering is that of Bayesian statistics (this relationship will be tackled in a later post).\n\n# The g-h filter\n\nBefore jumping into more advanced topics however it is good to start from the core mechanisms of **prediction** and **update** and the [g-h filter](https://en.wikipedia.org/wiki/Alpha_beta_filter) is the perfect tool for illustrating them.\n\n::: {#a800502b .cell execution_count=2}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\ndef sensors_plots(measurements_dict, show_expectation=True, current_ax=None, **scatter_kwargs):\n    if current_ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n    else:\n        ax = current_ax\n    expectation = 0\n    for sensor_number, (sensor, measurements) in enumerate(measurements_dict.items()):\n\n        mean_measurements = np.mean(measurements)\n        std_measurements = np.std(measurements)\n        expectation += mean_measurements\n\n        ax.scatter(\n            x=mean_measurements,\n            y=sensor_number,\n            label=sensor,\n            **scatter_kwargs\n        )\n        ax.errorbar(\n            x=mean_measurements,\n            y=sensor_number,\n            xerr=1.96 *std_measurements,\n            ls=\"none\"\n        )\n    \n    expectation = round(expectation / len(measurements_dict), 2)\n    if show_expectation:\n\n        ax.axvline(\n            expectation,\n            linestyle=\"--\",\n            c=\"r\",\n            label=f\"Expected Value {expectation}\"\n        )\n    \n    ax.legend()\n    ax.set_ylim(\n        - 2,\n        len(measurements_dict) + 1\n    )\n    ax.set_yticks([])\n    ax.set_xlabel(\"Measurement\")\n    ax.legend()\n    ax.tick_params(direction=\"in\", top=True, axis=\"x\", rotation=45)\n    ax.grid(\n        visible=True, \n        which=\"major\", \n        axis=\"x\", \n        color=\"k\", \n        alpha=0.25, \n        linestyle=\"--\"\n    )\n    if current_ax is None:\n        return fig, ax\n    else: \n        return ax\n\n\ndef time_series_plots(measurements, expected_noise, current_ax=None, dense_grid=True, scatter_kwargs={}, error_kwargs={}):\n    if current_ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n    else:\n        ax = current_ax\n    time = np.arange(len(measurements))\n    ax.scatter(\n        x=time,\n        y=measurements,\n        label=\"Measurements + Noise\",\n        **scatter_kwargs\n    )\n    ax.errorbar(\n        x=time,\n        y=measurements,\n        yerr=[1.96 *expected_noise for t in time],\n        ls=\"none\",\n        **error_kwargs\n    )\n    \n    if dense_grid:\n        ax.set_xticks(np.arange(len(time), step=0.5))\n    ax.set_ylabel(\"Measurement\")\n    ax.set_xlabel(\"Time\")\n    ax.legend()\n    ax.tick_params(direction=\"in\", top=True, axis=\"x\", rotation=45)\n    ax.grid(\n        visible=True, \n        which=\"major\", \n        axis=\"x\", \n        color=\"k\", \n        alpha=0.25, \n        linestyle=\"--\"\n    )\n    if current_ax is None:\n        return fig, ax\n    else: \n        return ax\n```\n:::\n\n\n## Combining noisy measurements\n\nLet's imagine to be in a situation in which we want to evaluate a certain phenomena using two sensors (or any measuring tool). We know that both sensors provide measures with an error margin of $\\pm 5$ units (expressed as standard deviations), so how can we obtain a reliable estimate of the state of the underlying phenomena?\n\nIn the absence of any other information, the most straightforward strategy here is to leverage the measurements provided by both sensors and compute the **expected** value.\n\n::: {#600b1a55 .cell execution_count=3}\n``` {.python .cell-code}\nmeasurements_dict = {\n    \"Sensor 1\": np.random.normal(30, 5, 50),\n    \"Sensor 2\": np.random.normal(20, 5, 50)\n}\n\nfig, ax = sensors_plots(\n    measurements_dict=measurements_dict, \n    show_expectation=True\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\nThe computed expected value gives us a more reasonable and robust estimate of the true state of the phenomena we are trying to measure. This because it is a value compatible with the measurements provided by both sensors.\n\nThis assumes both sensors to be equally trustworthy or in other words to have the same margin of error. In case we knew that one of the two sensors is sensibly more accurate than the other (let's say a margin of error of $\\pm 2.5$ units) we would probably expect it to contribute more to our estimate. However, surprisingly including some of the information provided by the less accurate sensor can give us an even better estimate!\n\n::: {#afbae814 .cell execution_count=4}\n``` {.python .cell-code}\nmeasurements_dict = {\n    \"Accurate Sensor\": np.random.normal(30, 2.5, 50),\n    \"Noisy Sensor\": np.random.normal(20, 5, 50)\n}\n\nfig, ax = sensors_plots(\n    measurements_dict=measurements_dict, \n    show_expectation=True\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){}\n:::\n:::\n\n\nIf we look at the overlap between the measurements provided by both sensors we can see that the region of acceptable values compatible with the two different measurements regimes is narrower than the one provided by the more accurate sensor alone!\n\nInterestingly, this region doesn't include the expected value from the accurate sensor and compute a naive average between the two provide an estimate that is incompatible with the observed measurements.\n\n***\n**Take Home Message**\n\nTwo measurements sources, even if one is less accurate, are better than one. Information is always used and never thrown away.\n\n***\n\n## Measurements and Predictions\n\nA more common situation however is observed sequential measurements from a single, potentially noisy sensor. Of course the more measurements we take the closer we should get to the actual state of the phenomena we are analyzing.\n\nUnfortunately in many situations we don't have this luxury. As we mentioned at the beginning of this post, in some situation we can only observe a handful of measurements (potentially only one!) like in the case of temporal series.\n\nIn a temporal series if our measurements happen to be at a frequency higher than the dynamics of the phenomena under investigation we are in a relatively comfortable position but otherwise we are going to be in a situation where information is sparse and vulnerable to noise.\n\n::: {#f1681693 .cell execution_count=5}\n``` {.python .cell-code}\nmeasurements = np.array([50, 60, 48, 49, 46, 42, 40])\n\nfig, ax = time_series_plots(\n    measurements=measurements,\n    expected_noise=5\n)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){}\n:::\n:::\n\n\nIf we were to use the same heuristics illustrated before, a jump of ~10 units between `Time 0`, `Time 1` and `Time 2` would be compatible with the observed measurements and their associated error bounds.\n\nDepending on the nature of the phenomena under investigation this might or might not be plausible. In order to verify this we need to \"blend\" the measurements provided by our noisy sensor with a model of the dynamics controlling our phenomena. Let's start with a very naive model.\n\n::: {#bb25271c .cell execution_count=6}\n``` {.python .cell-code}\nfig, ax = time_series_plots(\n    measurements=measurements,\n    expected_noise=5\n)\nax.plot(\n    np.arange(len(measurements)),\n    [50] * len(measurements),\n    linestyle=\":\",\n    color=\"k\",\n    label=\"Constant Dynamics\"\n)\nax.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){}\n:::\n:::\n\n\nIn this case we assume that the state underlying our phenomena stays constant over time, hence producing virtually no variations in the observed measurements.\n\nWe can already see how this, despite its simplicity, is already informing us that, under the assumptions of our model, the measurement at `Time 1` is likely to be driven by noise.\n\n***\n\n**Heads Up**\n\nIt is important to remember that the word *noise* doesn't necessary indicate the presence of an *error*. It rather represents variations that are not consistent with our model or that cannot be explained by the information we have at hand.\n\n***\n\nThat said, we can also clearly see how the assumptions of a constant dynamics model do not get along well with the available measurements, which seems to be characterized by a downward trend. So maybe let's try to draw the gradient line connecting the first to the last measurement\n\n::: {#c1d50830 .cell execution_count=7}\n``` {.python .cell-code}\ndef slope_model(beta, alpha, time):\n    \"\"\"Generate predictions according to a \n    simple linear model.\n\n    Args:\n        - beta(float): intercept value.\n        - alpha(float): slope value.\n        - time(np.array): time points.\n    \n    Returns:\n        - predictions (np.array): predictions generated by\n        the model.\n    \"\"\"\n    return beta + alpha * time\n\nnegative_slope_model = slope_model(\n    beta=50, \n    alpha=-1.7, \n    time=np.arange(len(measurements))\n)\n\nfig, ax = time_series_plots(\n    measurements=measurements,\n    expected_noise=5\n)\nax.plot(\n    np.arange(len(measurements)),\n    negative_slope_model,\n    linestyle=\":\",\n    color=\"k\",\n    label=\"Negative Slope Dynamics\"\n)\nax.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){}\n:::\n:::\n\n\nAlthough far from being perfect, this new model appears to provide a much better fit to our measurements. It is compatible with most of them or at least lies within the acceptable region defined by their error bounds. On top of that, having a model allows us to perform predictions about future measurements that we can then confront with actual observed values.\n\nHowever, we can see that the predictions from our negative slope model are not incompatible with the measurement provided at `Time 1`, what should we do in this case then? Should we simply disregard it? At the end of the day the model is just an artificial device plucked out of thin air (well, not exactly as it should be informed by our knowledge of the dynamics at play) while the measurement is the manifestation of real events. If we can exclude a completely faulty record, it still holds some information that we can use for improving our estimate.  \n\nIf both measurements and model's predictions are identical one of the two becomes redundant. However, as soon as we observe discrepancies between them we know that there is information that can be gained. So what should we trust in this situation, the predictions or the measurements?\n\n***\n\n**Take Home Message**\n\nNo source of information must be ignored, a better estimate can be achieved by **blending** model predictions and measurements. Two measurements are better than one.\n\n***\n\n## Blending Measurements and predictions\n\nSo how should this blending happen? A reasonable strategy would be to weight more the source of information that we believe to be more reliable. Let's look at how we can formalize this in python code. From here on we will occasionally rely on JAX for making our code more efficient (we won't spend time describing what JAX is, we recommend checking out the [documentation page](https://jax.readthedocs.io)).\n\n::: {#798b821d .cell execution_count=8}\n``` {.python .cell-code}\nfrom jax import jit\nfrom jax.lax import scan\n\nimport jax.numpy as jnp\n\nfrom jax import random\n\n\n@jit\ndef custom_gain_model(measurements, starting_estimate, gain_rate, scale_factor, gain_update_frequency):\n    \"\"\"Create a custom gain model. It will iteratively estimate \n    the state underlying the observed measurements. The function will be JIT compiled for increasing execution time.\n\n    Args:\n        - measurements (np.array): observed measurements\n        - starting_estimate (float): the starting point \n        for the estimate.\n        - gain_rate (float): the time dependent increase in estimate, it correspond to the slope of the slope_model.\n        - gain_update_frequency (float): time steps required for having a full update \n        of the gain.\n        - scale_factor (float): scale applied to weight the measurements.\n    \n    Returns:\n        - estimated_states(np.array): estimated states underlying the measurements.\n    \"\"\"\n    @jit\n    def step(carry, measurement):\n        \"\"\"Step function for computing the estimate, this will be iterated\n        over all the measurements. The arguments required for estimating the \n        state will be provided by the carry.\n        \"\"\"\n        previous_estimate, gain_update_frequency, gain_rate, scale_factor = carry\n        prediction = previous_estimate + gain_rate * gain_update_frequency\n\n        new_estimate = prediction + scale_factor * (measurement - prediction)\n        \n        new_carry = (new_estimate, gain_update_frequency, gain_rate, scale_factor)\n        output = jnp.array([new_estimate, prediction])\n\n        return new_carry, output\n\n    _, output = scan(\n        step,\n        (starting_estimate, gain_update_frequency, gain_rate, scale_factor),\n        measurements\n    )\n\n    estimated_states = output[:, 0]\n    predictions = output[:, 1]\n\n    return estimated_states, predictions\n\nmeasurements = 50 + np.arange(10) * -1.7\nmeasurements += random.normal(\n    key=random.PRNGKey(666), \n    shape=(len(measurements),)\n) * 5\n\nestimated_states, predictions = custom_gain_model(\n    measurements=measurements, \n    gain_update_frequency=1.,\n    starting_estimate=50., \n    gain_rate=-1.7, \n    scale_factor=.3\n)\nestimated_states = np.array(estimated_states)\npredictions = np.array(predictions)\n```\n:::\n\n\nIn this case we used as gain rate the slope of our previous `slope_model` and expressed a belief that the predictions of our model are to be trusted more than the measurements. Precisely that the discrepancy between prediction and measurement should contribute only by `30%` to the overall estimate.\n\n::: {#4300e1fd .cell execution_count=9}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nfig, ax = time_series_plots(\n    measurements=measurements,\n    expected_noise=5\n)\nax.plot(\n    np.arange(len(measurements)),\n    estimated_states,\n    linestyle=\"--\",\n    color=\"r\",\n    label=\"Estimated States\"\n)\nax.plot(\n    np.arange(len(measurements)),\n    predictions,\n    linestyle=\":\",\n    color=\"r\",\n    marker=\"*\",\n    label=\"Predictions\"\n)\nax.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){}\n:::\n:::\n\n\nBy varying our belief, expressed through the `gain_rate` we can obtain estimates that are more or less influenced by either the dynamics' model or by the measurements.\n\n::: {#b8a46421 .cell execution_count=10}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nimport matplotlib\n\ncolor_mapper = matplotlib.cm.get_cmap('Dark2')\n\nfig, ax = time_series_plots(\n    measurements=measurements,\n    expected_noise=5\n)\n\nfor index, scale_factor in enumerate([.4, .6, .8,]):\n\n    estimated_states, predictions = custom_gain_model(\n        measurements=measurements, \n        starting_estimate=52., \n        gain_rate=-1.7, \n        gain_update_frequency=1.,\n        scale_factor=scale_factor\n    )\n    estimated_states = np.array(estimated_states)\n    ax.plot(\n        np.arange(len(measurements)),\n        estimated_states,\n        c=color_mapper(index),\n        linestyle=\"--\",\n        label=f\"Scale Factor {scale_factor}\"\n    )\n    ax.plot(\n        np.arange(len(measurements)),\n        predictions,\n        c=color_mapper(index),\n        linestyle=\":\",\n        marker=\"*\",\n        label=f\"Predictions {scale_factor}\"\n    )\nax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/h_/lq2hvf816xs9ffng6570sblh0000gn/T/ipykernel_5995/1561832762.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  color_mapper = matplotlib.cm.get_cmap('Dark2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-11-output-2.png){}\n:::\n:::\n\n\nhere we used as `gain_rate` a fixed value of `-1.7` as it was the slope of the linear model we used for simulating our measurements. However, having a fixed gain rate is quite an inflexible strategy which becomes particular ineffective when the rate of change varies dynamically. To circumvent this issue, we can let the `gain_rate` parameter varies based on how far are the predictions of our model dynamic from the observed measurement.\n\n::: {#09588fe4 .cell execution_count=11}\n``` {.python .cell-code}\n@jit\ndef adaptive_gain_model(measurements, starting_estimate, starting_gain, gain_factor, gain_update_frequency, scale_factor):\n    \"\"\"Create an adaptive gain model. It will iteratively estimate \n    the state underlying the observed measurements and compute the gain adaptively based on the mismatch between prediction and measurement. \n    The function will be JIT compiled for increasing execution time.\n\n    Args:\n        - measurements (np.array): observed measurements\n        - starting_estimate (float): the starting point \n        for the estimate.\n         - starting_gain (float): the starting point \n        for the gain.       \n        - gain_factor (float): factor used for adaptively update the gain.\n        - gain_update_frequency (float): time steps required for having a full update \n        of the gain.\n        - scale_factor (float): scale applied to weight the measurements.\n    \n    Returns:\n        - estimated_states(np.array): estimated states underlying the measurements.\n    \"\"\"\n    @jit\n    def step(carry, measurement):\n        \"\"\"Step function for computing the estimate, this will be iterated\n        over all the measurements. The arguments required for estimating the \n        state will be provided by the carry.\n        \"\"\"\n        (\n            previous_estimate, \n            previous_gain, \n            gain_update_frequency, \n            gain_factor, \n            scale_factor\n         ) = carry\n        \n        prediction = previous_estimate + previous_gain * gain_update_frequency\n        residual = measurement - prediction\n\n        new_estimate = prediction + scale_factor * (residual)\n        new_gain = previous_gain + gain_factor * (residual / gain_update_frequency)\n        \n        new_carry = (\n            new_estimate, \n            new_gain, \n            gain_update_frequency, \n            gain_factor, \n            scale_factor\n        )\n        output = jnp.array([new_gain, new_estimate, prediction])\n\n        return new_carry, output\n\n    _, output = scan(\n        step,\n        (starting_estimate, starting_gain, gain_update_frequency, gain_factor, scale_factor),\n        measurements\n    )\n\n    gains = output[:, 0]\n    estimated_states = output[:, 1]\n    predictions = output[:, 2]\n\n    return gains, estimated_states, predictions\n\ngains, estimated_states, predictions = adaptive_gain_model(\n    measurements=measurements, \n    gain_update_frequency=1.,\n    starting_estimate=50., \n    starting_gain=-1.7, \n    scale_factor=.6,\n    gain_factor=.1\n)\n\ngains = np.array(gains)\nestimated_states = np.array(estimated_states)\npredictions = np.array(predictions)\n```\n:::\n\n\nIn this new version of `custom_gain_model` we let the `gain` (which can grossly be compared with the slope of our original `slope_model`) be a fraction (controlled by `gain_factor`) of the residuals derived from predictions and observed measurements. As before this `new_gain` parameter controls how much belief we put in either the model or the observed measurements but instead of setting its value statically we let it adapt based on the performance of the model so that if our initial guess results to be inadequate at a certain point in time (e.g. due to abrupt changes in the state dynamics) the model can correct itself.\n\n::: {#aa07119e .cell execution_count=12}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\nfrom matplotlib.gridspec import GridSpec\n\nfig = plt.figure(figsize=(8, 5))\nspec = GridSpec(2, 2, figure=fig)\n\nax_state = fig.add_subplot(spec[0, :])\nax_predictions = fig.add_subplot(spec[1, 0])\nax_gains = fig.add_subplot(spec[1, 1])\n\nfor ax in [ax_state, ax_predictions]:\n\n    ax = time_series_plots(\n        measurements=measurements,\n        expected_noise=5,\n        current_ax=ax\n    )\n\nax_state.plot(\n    np.arange(len(measurements)),\n    estimated_states,\n    linestyle=\"--\",\n    color=\"r\",\n    label=\"Estimated States\"\n)\nax_state.legend()\nax_predictions.plot(\n    np.arange(len(measurements)),\n    predictions,\n    linestyle=\"--\",\n    color=\"r\",\n    label=\"Predictions\"\n)\nax_predictions.legend()\n\nax_gains.plot(\n    np.arange(len(measurements)),\n    gains,\n    linestyle=\"--\",\n    color=\"r\",\n    label=\"Gains\"\n)\nax_gains.legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){}\n:::\n:::\n\n\n## Finally to the g-h Filter\n\nThe `adaptive_gain_model` is basically equivalent to the g-h filter we introduced at the beginning of this post. The `g` and `h` are the scaling factors that we introduced in our function, namely the `scale_factor` (weighting the contribution of the the observed measurements) and the `gain_factor` (scaling the change in state estimate over time).\n\n***\n\n**Take Home Message**\n\nThe key points underlying the algorithm summarize what we highlighted until here\n\n1. More data points are better than less\n2. No data must be thrown away, no information must be discarded.\n3. The middle point between two value can give a more accurate estimate.\n4. Measurement will be predicted along with rate of change based on current state estimate and how much change we will expect in the future.\n5. The new estimate will be generated as a middle point between measurement and estimated state, giving more weight to the more accurate of the two.\n\n***\n\nWhat is the target of our estimation efforts is what is called the **system**. We can think of it as the data generating process, for example given a time series of GDP for a nation the system might be the economy of that nation. The **state** is the current configuration of the **system** at a given point in time, for example the estimated GDP for the year 2008, it is usually hidden to us. The **measurements** are quantitative description of the state of the system, they are often noisy so they might not coincide with the state, we can think of them as observable manifestations of the state. \n\n***\n\n**Take Home Message**\n\nAs in eny estimation problem, the aim of a filtering algorithm is to form estimates of the hidden state of the system given some observable information.\n\n***\n\nIn order to generate our estimate we need to alternate between a **prediction step** and an **update step**. \n\nIn the prediction step we use a **process model** (in our case was the `slope_model`) for mathematically describing how the system evolves, this model is used for propagating the state of the system into the future. The model has an intrinsic amount of unknown **process error** that might be caused by imperfect measurements or inadequate process model (we must remember that all models are wrong!).\n\n***\n\n**Take Home Message**\n\nA filtering algorithm is as good as the mathematical model used for expressing our beliefs about the system dynamics. \n\n***\n\nIn the update step we update the propagated state with the information derived from the measurement.\n\nWe can have a better understanding of the various steps by looking at a graphical representation of the algorithm\n\n\n```{mermaid}\nflowchart LR    \n   predict(((Predict Step)))\n   update(((Update Step)))\n   estimate((State Estimate\\nt1))\n   prediction((State Prediction\\nt1))\n   init((Initialisation\\nt0))\n   measurement((Measurement\\nt1))\n\n   init --> predict;\n   predict ----> prediction;\n   prediction ----> update;\n   measurement --> update;\n   update ----> estimate;\n   estimate --> predict\n```\n\n\nWe will now re-write the `adaptive_gain_model` into the `gh_filter` by making the steps outlined in the diagram above a little bit more explicit\n\n::: {#3fac4ac2 .cell execution_count=13}\n``` {.python .cell-code}\n@jit\ndef gh_filter(measurements, starting_state, starting_gain, gain_factor, gain_update_frequency, state_factor):\n    \"\"\"Create the gh filter model. It will iteratively estimate \n    the state underlying the observed measurements and compute the gain adaptively based on the mismatch between prediction and measurement. \n    The function will be JIT compiled for increasing execution time.\n\n    Args:\n        - measurements (np.array): observed measurements\n        - starting_estimate (float): the starting point \n        for the estimate.\n         - starting_gain (float): the starting point \n        for the gain.       \n        - gain_factor (float): factor used for adaptively update the gain.\n        - gain_update_frequency (float): time steps required for having a full update \n        of the gain.\n        - state_factor (float): scale applied to weight the measurements.\n    \n    Returns:\n        - estimated_states(np.array): estimated states underlying the measurements.\n    \"\"\"\n    @jit\n    def predict(state_estimate, gain, gain_update_frequency):\n        \"\"\"Perform the predict step of the algorithm. Gain will not really be\n        predicted.\n        \"\"\"\n        state_predicted = state_estimate + gain * gain_update_frequency\n        gain_predicted = gain\n        return state_predicted, gain_predicted\n\n    def update(state_predicted, gain_predicted, state_factor, gain_factor, gain_update_frequency, residual):\n        \"\"\"Perform the update step of the algorithm.\n        \"\"\"\n        state_updated = state_predicted + state_factor * (residual)\n        gain_updated = gain_predicted + gain_factor * (residual / gain_update_frequency)\n        return state_updated, gain_updated\n\n    @jit\n    def step(carry, measurement):\n        \"\"\"Step function for computing the estimate, this will be iterated\n        over all the measurements. The arguments required for estimating the \n        state will be provided by the carry.\n        \"\"\"\n        (\n            previous_state, \n            previous_gain, \n            gain_update_frequency, \n            gain_factor, \n            state_factor\n         ) = carry\n        \n        state_predicted, gain_predicted = predict(\n            state_estimate=previous_state, \n            gain=previous_gain, \n            gain_update_frequency=gain_update_frequency\n        )\n\n        residual = measurement - state_predicted\n\n        state_updated, gain_updated = update(\n            state_predicted=state_predicted, \n            gain_predicted=gain_predicted, \n            state_factor=state_factor, \n            gain_factor=gain_factor, \n            gain_update_frequency=gain_update_frequency, \n            residual=residual\n        )\n \n        new_carry = (\n            state_updated, \n            gain_updated, \n            gain_update_frequency, \n            gain_factor, \n            state_factor\n        )\n        output = jnp.array([state_updated, state_predicted, gain_updated])\n\n        return new_carry, output\n\n    _, output = scan(\n        step,\n        (\n            starting_state, \n            starting_gain, \n            gain_update_frequency, \n            gain_factor, \n            state_factor\n        ),\n        measurements\n    )\n\n    states_estimated = output[:, 0]\n    states_predicted = output[:, 1]\n    gains_estimated = output[:, 2]\n\n    return gains_estimated, states_estimated, states_predicted\n```\n:::\n\n\nas we can the the algorithm is exactly the same, we just made each step be represented by an appropriate closure (this is needed for making JAX happy). So how do we pick and optimal value of `state_factor` and `gain_factor`? Well this is problem dependent but it can be informed by the effect that these two parameters have on the estimate\n\n1. `state_factor` (`g`): as this parameter gets larger we will tend to more closely follow (i.e. we will weight more) the measurement. A value too high will lead us to over-fit to the noise while a value too low will force us to ignore important information about changes in the system dynamics.\n\n2. `gain_factor` (`h`): as this parameter gets larger we will tend to react more quickly to sudden changes in the dynamics underlying our measurements. A value too high might cause to over-react producing spurious high-frequency spikes in the estimate while a value too low might cause the signal to adapt very slowly to sudden changes in the measurements (i.e., the estimate will take a long time to correct itself).\n\n## Examples\n\nLet's try to get a visual intuition of the effect of varying `state_factor` and `gain_factor` in different situations.\n\n::: {#9d1937b9 .cell execution_count=14}\n``` {.python .cell-code code-fold=\"true\" code-summary=\"Show supplementary code\"}\ndef plot_estimated_states(measurements, measurement_noise, estimated_states_dict, ax):\n    color_mapper = matplotlib.cm.get_cmap('Dark2')\n    ax = time_series_plots(\n        measurements=measurements,\n        expected_noise=measurement_noise,\n        dense_grid=False,\n        current_ax=ax,\n        scatter_kwargs={\n            \"alpha\": 0.2,\n            \"s\": 2\n        },\n        error_kwargs={\n            \"alpha\": 0.2\n        },       \n    )\n    for index, (model_name, estimated_states) in enumerate(estimated_states_dict.items()):\n\n        ax.plot(\n            np.arange(len(measurements)),\n            estimated_states,\n            c=color_mapper(index),\n            linestyle=\"--\",\n            label=f\"Estimated States {model_name}\",\n        )\n    ax.legend()\n    return ax\n\ndef run_example(measurements, gain_factors, state_factors, measurement_noise=5):\n    estimated_states_dict = {}\n    for (gain_factor, state_factor) in list(product(gain_factors, state_factors)):\n\n        gains, estimated_states, predictions = gh_filter(\n            measurements=measurements, \n            starting_state=5., \n            starting_gain=1., \n            gain_factor=gain_factor, \n            state_factor=state_factor,\n            gain_update_frequency=1\n\n        )\n        estimated_states_dict[f\"g: {state_factor} h: {gain_factor}\"] = estimated_states\n\n    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n    ax = plot_estimated_states(\n        measurements=measurements, \n        measurement_noise=measurement_noise, \n        estimated_states_dict=estimated_states_dict, \n        ax=ax\n    )\n\n    return fig, ax\n```\n:::\n\n\n### Example 1 - Derivative Change\n\n::: {#dc1770d8 .cell execution_count=15}\n``` {.python .cell-code}\nmeasurements = (0 + jnp.arange(100) * 1.3) + random.normal(shape=(100,), key=random.PRNGKey(666)) * 5.\nmeasurements = jnp.clip(measurements, None, 100)\n\nfig, ax = run_example(\n    measurements=measurements, \n    gain_factors=[.3, .6], \n    state_factors=[.3, .6]\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/h_/lq2hvf816xs9ffng6570sblh0000gn/T/ipykernel_5995/3276693041.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  color_mapper = matplotlib.cm.get_cmap('Dark2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-16-output-2.png){}\n:::\n:::\n\n\n### Example 2 - Level Shift\n\n::: {#10e4f8f5 .cell execution_count=16}\n``` {.python .cell-code}\nmeasurements = (0 + jnp.arange(50) * 1.03) + random.normal(shape=(50,), key=random.PRNGKey(666)) * 5.\nmeasurements = jnp.hstack(\n    (\n        measurements, \n        jnp.repeat(measurements[-1] * 3, 25)  + random.normal(shape=(25,), key=random.PRNGKey(666)) * 5.\n    )\n)\nmeasurements = jnp.hstack(\n    (\n        measurements, \n        jnp.repeat(measurements[-1] / 3.5, 25) + random.normal(shape=(25,), key=random.PRNGKey(666)) * 5.\n    )\n) \n\nfig, ax = run_example(\n    measurements=measurements, \n    gain_factors=[.3, .6], \n    state_factors=[.3, .6]\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/h_/lq2hvf816xs9ffng6570sblh0000gn/T/ipykernel_5995/3276693041.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  color_mapper = matplotlib.cm.get_cmap('Dark2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-2.png){}\n:::\n:::\n\n\n### Example 3 - Inadequate System Model (Dynamics with acceleration) \n\n::: {#0f827485 .cell execution_count=17}\n``` {.python .cell-code}\ntime = jnp.arange(5)\nmeasurements = 0 + (time * 1.03) + (jnp.power(time, 2) * 6) + random.normal(shape=(5,), key=random.PRNGKey(666)) * 5.\n\n\nfig, ax = run_example(\n    measurements=measurements, \n    gain_factors=[.3, .6], \n    state_factors=[.3, .6]\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/h_/lq2hvf816xs9ffng6570sblh0000gn/T/ipykernel_5995/3276693041.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  color_mapper = matplotlib.cm.get_cmap('Dark2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-2.png){}\n:::\n:::\n\n\n### Example 4 - Extreme Noise\n\n::: {#50fd3ac9 .cell execution_count=18}\n``` {.python .cell-code}\nmeasurements = (0 + jnp.arange(100) * 1.3) + random.normal(shape=(100,), key=random.PRNGKey(666)) * 50.\n\nfig, ax = run_example(\n    measurements=measurements, \n    gain_factors=[.3, .6], \n    state_factors=[.3, .6],\n    measurement_noise=50\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/var/folders/h_/lq2hvf816xs9ffng6570sblh0000gn/T/ipykernel_5995/3276693041.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  color_mapper = matplotlib.cm.get_cmap('Dark2')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-2.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}